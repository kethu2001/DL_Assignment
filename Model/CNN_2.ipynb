{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0eba36-0342-436e-b804-6a40c332604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split_folders in d:\\anaconda\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8883c17c-616b-4c18-9fef-340dc682e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70615c93-fcd7-4086-9347-c705cec5db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 15515 files [00:56, 274.88 files/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"C:\\Users\\Ishan's MSi\\Desktop\\Dataset\\garbage_classification\"\n",
    "output = r\"C:\\Users\\Ishan's MSi\\Desktop\\Dataset\\process_data\"\n",
    "splitfolders.ratio(input_folder, output, seed=42, ratio=(.6, .2, .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d1d797-21ee-4c07-9db5-4bbdf3406129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ratio in module splitfolders.split:\n",
      "\n",
      "ratio(input, output='output', seed=1337, ratio=(0.8, 0.1, 0.1), group_prefix=None, move=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(splitfolders.ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a55cb4-fbf9-410f-b45b-db2dfb7494c6",
   "metadata": {},
   "source": [
    "#Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2c363e-f926-46b5-ad50-6c33c95b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b07d09-3468-4a02-98c7-ef299ffd3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape=(224, 224, 3), num_classes=12):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional Layer 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten the layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Fully connected layer\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Output layer with softmax activation\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a982b1c1-d315-46d2-9ca5-42a197e5c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "def save_model(model, filepath='garbage_classification_model.h5'):\n",
    "    model.save(filepath)\n",
    "    print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d069c34-815e-4e72-8e81-af33e42a2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9307 images belonging to 12 classes.\n",
      "Found 3100 images belonging to 12 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 1s/step - accuracy: 0.4045 - loss: 1.8932 - val_accuracy: 0.5785 - val_loss: 1.2407\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/290\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 357ms/step - accuracy: 0.5625 - loss: 1.0868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.0868 - val_accuracy: 0.5000 - val_loss: 1.7006\n",
      "Epoch 3/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 763ms/step - accuracy: 0.5823 - loss: 1.2859 - val_accuracy: 0.6517 - val_loss: 1.1113\n",
      "Epoch 4/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.6250 - loss: 1.0864 - val_accuracy: 0.6786 - val_loss: 1.1818\n",
      "Epoch 5/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 674ms/step - accuracy: 0.6249 - loss: 1.1390 - val_accuracy: 0.6478 - val_loss: 1.0725\n",
      "Epoch 6/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.5938 - loss: 1.2816 - val_accuracy: 0.6071 - val_loss: 1.3252\n",
      "Epoch 7/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 775ms/step - accuracy: 0.6588 - loss: 1.0428 - val_accuracy: 0.7103 - val_loss: 0.9011\n",
      "Epoch 8/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7188 - loss: 0.8011 - val_accuracy: 0.7857 - val_loss: 0.5695\n",
      "Epoch 9/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 720ms/step - accuracy: 0.6908 - loss: 0.9684 - val_accuracy: 0.7148 - val_loss: 0.8854\n",
      "Epoch 10/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6562 - loss: 0.9161 - val_accuracy: 0.7857 - val_loss: 0.8646\n",
      "Epoch 11/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 718ms/step - accuracy: 0.7020 - loss: 0.9214 - val_accuracy: 0.7308 - val_loss: 0.8442\n",
      "Epoch 12/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.8125 - loss: 0.7567 - val_accuracy: 0.6429 - val_loss: 0.8916\n",
      "Epoch 13/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 669ms/step - accuracy: 0.7250 - loss: 0.8409 - val_accuracy: 0.7311 - val_loss: 0.8731\n",
      "Epoch 14/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7500 - loss: 0.6404 - val_accuracy: 0.7857 - val_loss: 0.8492\n",
      "Epoch 15/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 603ms/step - accuracy: 0.7308 - loss: 0.8225 - val_accuracy: 0.7474 - val_loss: 0.8189\n",
      "Epoch 16/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.6562 - loss: 0.9807 - val_accuracy: 0.7143 - val_loss: 1.0754\n",
      "Epoch 17/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 614ms/step - accuracy: 0.7303 - loss: 0.8011 - val_accuracy: 0.7552 - val_loss: 0.7838\n",
      "Epoch 18/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7188 - loss: 0.8757 - val_accuracy: 0.7857 - val_loss: 0.6322\n",
      "Epoch 19/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 606ms/step - accuracy: 0.7538 - loss: 0.7402 - val_accuracy: 0.7679 - val_loss: 0.7367\n",
      "Epoch 20/20\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.8125 - loss: 0.7116 - val_accuracy: 0.8571 - val_loss: 0.6118\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - accuracy: 0.7652 - loss: 0.7035\n",
      "Validation accuracy: 76.81%\n",
      "Found 3108 images belonging to 12 classes.\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 474ms/step\n",
      "Confusion Matrix\n",
      "[[ 15   7   7  15  64   9   5  13  11  30   8   5]\n",
      " [ 10   9  10  11  62  13  11  12  11  34   6   8]\n",
      " [ 12   8   6   8  45   8   3   5   5  14   4   4]\n",
      " [  8   7   7  18  52   6   8  10   9  32  10  12]\n",
      " [ 72  60  41  64 396  60  48  65  51 125  41  42]\n",
      " [  8   9   6  12  46   6   3  10   9  10   7   1]\n",
      " [  5  12   6  11  61   6   5  11   7  16   9   6]\n",
      " [ 14  13   5  12  84  11  15  15   7  22   6   6]\n",
      " [ 11   8  11   9  64  10   5   4  12  27   7   5]\n",
      " [ 23  22   7  29 156  15  15  34  24  44   9  18]\n",
      " [ 13   8   5   6  50   6   3  12   4  18  13   2]\n",
      " [  7   7   8   7  64   4   3  14   7  22   5   7]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.08      0.08      0.08       189\n",
      "  biological       0.05      0.05      0.05       197\n",
      " brown-glass       0.05      0.05      0.05       122\n",
      "   cardboard       0.09      0.10      0.09       179\n",
      "     clothes       0.35      0.37      0.36      1065\n",
      " green-glass       0.04      0.05      0.04       127\n",
      "       metal       0.04      0.03      0.04       155\n",
      "       paper       0.07      0.07      0.07       210\n",
      "     plastic       0.08      0.07      0.07       173\n",
      "       shoes       0.11      0.11      0.11       396\n",
      "       trash       0.10      0.09      0.10       140\n",
      " white-glass       0.06      0.05      0.05       155\n",
      "\n",
      "    accuracy                           0.18      3108\n",
      "   macro avg       0.09      0.09      0.09      3108\n",
      "weighted avg       0.17      0.18      0.17      3108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define image size, batch size, epochs, and learning rate\n",
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define the directories for the dataset (train, validation, test)\n",
    "train_dir = r\"C:\\Users\\Ishan's MSi\\Desktop\\Dataset\\process_data\\train\"\n",
    "val_dir = r\"C:\\Users\\Ishan's MSi\\Desktop\\Dataset\\process_data\\val\"\n",
    "test_dir = r\"C:\\Users\\Ishan's MSi\\Desktop\\Dataset\\process_data\\test\"\n",
    "\n",
    "\n",
    "# Pre-processing and data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Creating data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional and Pooling layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers and adding fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Helps to prevent overfitting\n",
    "model.add(Dense(12, activation='softmax'))  # 12 classes for classification\n",
    "\n",
    "# Compiling the model\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f'Validation accuracy: {val_acc * 100:.2f}%')\n",
    "\n",
    "# Test on test data\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = Y_pred.argmax(axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = list(train_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c850c0ef-17a6-4da8-8c7b-1dacc8d5fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tk\n",
      "  Downloading tk-0.1.0-py3-none-any.whl.metadata (693 bytes)\n",
      "Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
      "Installing collected packages: tk\n",
      "Successfully installed tk-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07055f3-8d79-426a-8c64-7199e738ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk, messagebox\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "# Use tkinter to open a file dialog to select the model file\n",
    "Tk().withdraw()  # We don't want a full GUI, so keep the root window from appearing\n",
    "model_path = askopenfilename(title=\"Select .h5 model file\", filetypes=[(\"H5 files\", \"*.h5\")])\n",
    "\n",
    "if not model_path:\n",
    "    messagebox.showerror(\"Error\", \"No file selected. Please select a valid .h5 file.\")\n",
    "    raise SystemExit(\"Exiting program due to missing file.\")\n",
    "\n",
    "try:\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded successfully from {model_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Assuming you have the test_generator and train_generator objects ready\n",
    "# Below code assumes you have set them up correctly before running this part\n",
    "\n",
    "# Prediction and Confusion Matrix\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(test_generator)\n",
    "\n",
    "y_prob = []\n",
    "y_act = []\n",
    "\n",
    "test_generator.reset()  # Resetting test generator to start from the first batch\n",
    "for _ in range(nb_samples):\n",
    "    X_test, y_test = next(test_generator)  # Get the next batch\n",
    "    y_prob.append(model.predict(X_test))   # Predict the output\n",
    "    y_act.append(y_test)                   # Collect the actual values\n",
    "\n",
    "# Ensure numpy array conversion for predictions and actual values\n",
    "y_prob = np.array(y_prob).reshape(-1, len(train_generator.class_indices))  # Flatten the list\n",
    "y_act = np.array(y_act).reshape(-1, len(train_generator.class_indices))\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_prob]\n",
    "actual_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_act]\n",
    "\n",
    "# Create a DataFrame for the actual vs predicted classes\n",
    "out_df = pd.DataFrame(np.vstack([predicted_class, actual_class]).T, columns=['predicted_class', 'actual_class'])\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = pd.crosstab(out_df['actual_class'], out_df['predicted_class'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, cmap=\"Blues\", annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print test accuracy\n",
    "accuracy = np.diag(confusion_matrix).sum() / confusion_matrix.sum().sum() * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee2816-6783-463b-b159-9b3382223887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model.save('CNN_garbage_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72d2fb-4247-4fb6-b451-72df18bda09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "test_dir = r\"D:\\\"\n",
    "\n",
    "# ImageDataGenerator for test set\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get the number of test samples\n",
    "nb_samples = test_generator.samples\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "y_prob = []\n",
    "y_act = []\n",
    "\n",
    "# Reset test generator before making predictions\n",
    "test_generator.reset()\n",
    "\n",
    "# Loop through test data and predict\n",
    "for _ in range(nb_samples // test_generator.batch_size):\n",
    "    X_test, y_test = next(test_generator)  # Get next batch of images\n",
    "    y_prob.append(model.predict(X_test))  # Predict probabilities\n",
    "    y_act.append(y_test)  # Append actual labels\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_prob = np.concatenate(y_prob)\n",
    "y_act = np.concatenate(y_act)\n",
    "\n",
    "# Get predicted and actual class indices\n",
    "predicted_class = np.argmax(y_prob, axis=1)\n",
    "actual_class = np.argmax(y_act, axis=1)\n",
    "\n",
    "# Mapping class indices to class names\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "predicted_class_names = [class_labels[i] for i in predicted_class]\n",
    "actual_class_names = [class_labels[i] for i in actual_class]\n",
    "\n",
    "# Create a DataFrame for the actual vs predicted classes\n",
    "out_df = pd.DataFrame({\n",
    "    'predicted_class': predicted_class_names,\n",
    "    'actual_class': actual_class_names\n",
    "})\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_mtx = pd.crosstab(out_df['actual_class'], out_df['predicted_class'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, cmap=\"Blues\", annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print test accuracy\n",
    "accuracy = np.diag(confusion_mtx).sum() / confusion_mtx.sum().sum() * 100\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Generate and print classification report\n",
    "print('Classification Report')\n",
    "print(classification_report(actual_class_names, predicted_class_names, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cfb56-5755-4153-81cc-661d8b64e1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
